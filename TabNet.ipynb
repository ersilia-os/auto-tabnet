{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM56+0CM+l1PdBV3yoEI7ig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ersilia-os/auto-tabnet/blob/main/TabNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CXSJOfotL7y",
        "outputId": "3cf4bd0e-49e5-4f72-d9de-1f4e3589cca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.9.3-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.12.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.3 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting umap\n",
            "  Downloading umap-0.1.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: umap\n",
            "  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3565 sha256=a2cca22940aa4db53c9f1cb49ee7e1f1d96d56c486c3cf3015b64b8cea214ecf\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/13/91/2e752dc8dab5df027854bd33d2b65e1dc5cdc107fd1133990f\n",
            "Successfully built umap\n",
            "Installing collected packages: umap\n",
            "Successfully installed umap-0.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.7.3)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (0.56.4)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from umap-learn) (4.64.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.49->umap-learn) (3.12.1)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=9008ee51dd1a07704e4f83aa2c8773802f7ff6765e7f0b8d00cf6114287d5a07\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/3a/67/06a8950e053725912e6a8c42c4a3a241410f6487b8402542ea\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=10a3320f217281799a185487ad71d7d41224f6804ab7f05a7a98e0ed9fb227c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/3a/29954bca1a27ba100ed8c27973a78cb71b43dc67aed62e80c3\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.8 umap-learn-0.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (1.21.6)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (1.7.3)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (4.64.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.4.0)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "!pip install umap\n",
        "!pip install umap-learn\n",
        "!pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from pytorch_tabnet.metrics import Metric\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn import preprocessing\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn import datasets\n",
        "from sklearn import model_selection\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "from pathlib import Path\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "dhlM34V0vlFE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_wC8Ewtvqj1",
        "outputId": "6099039b-25e4-45fb-bc14-fc6bac6d158a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datax=pd.read_csv('/content/drive/MyDrive/Gesture_Data.csv')\n",
        "li=['feature_'+str(i) for i in range(28)]\n",
        "li.append(\"output\")\n",
        "datax.columns=li\n",
        "datax.dropna(how='any',inplace=True)\n",
        "for col in datax.columns:\n",
        "  datax[col].astype('float32')\n",
        "num = [*(x for x in datax.columns if x.isnumeric())]\n",
        "for col in num:\n",
        "    sel = QuantileTransformer(n_quantiles=1000,random_state=0,output_distribution='normal')\n",
        "    sel.fit(datax[col].to_numpy().reshape(-1,1))\n",
        "    datax[col] = sel.transform(datax[col].to_numpy().reshape(-1,1))"
      ],
      "metadata": {
        "id": "Fcz4DuOIxraK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datax.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "qAxsvEm96sR1",
        "outputId": "f3000840-caff-42b6-8b64-0fe64d03ba08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0    0.07817    0.76526    0.07493    0.36647    0.69386    0.35531   \n",
              "1    0.06535    0.78984    0.07117    0.38040    0.74147    0.35050   \n",
              "2    0.06517    0.80187    0.06258    0.39622    0.74955    0.34247   \n",
              "3    0.06456    0.87456    0.07095    0.37056    0.71750    0.34110   \n",
              "4    0.07624    0.76268    0.06660    0.33706    0.69465    0.37617   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_19  feature_20  \\\n",
              "0    0.71839    0.46066         40         14  ...          89     0.00685   \n",
              "1    0.73124    0.45126         44         14  ...          88     0.00683   \n",
              "2    0.76792    0.44406         46         15  ...          86     0.00684   \n",
              "3    0.74416    0.44714         47         15  ...          82     0.00746   \n",
              "4    0.75712    0.48599         42         17  ...          85     0.00756   \n",
              "\n",
              "   feature_21  feature_22  feature_23  feature_24  feature_25  feature_26  \\\n",
              "0     0.02819     0.00718     0.01859     0.76616     1.20575     0.76821   \n",
              "1     0.02827     0.00668     0.01906     0.74031     1.26830     0.74396   \n",
              "2     0.02981     0.00721     0.01841     0.75492     1.29168     0.74225   \n",
              "3     0.02774     0.00695     0.01738     0.73082     1.34581     0.77579   \n",
              "4     0.02682     0.00747     0.01779     0.74330     1.32099     0.78662   \n",
              "\n",
              "   feature_27  output  \n",
              "0     1.12635       1  \n",
              "1     1.13324       1  \n",
              "2     1.11862       1  \n",
              "3     1.09954       1  \n",
              "4     1.14457       1  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3886804-2be2-4222-9f94-d47cd515e41e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.07817</td>\n",
              "      <td>0.76526</td>\n",
              "      <td>0.07493</td>\n",
              "      <td>0.36647</td>\n",
              "      <td>0.69386</td>\n",
              "      <td>0.35531</td>\n",
              "      <td>0.71839</td>\n",
              "      <td>0.46066</td>\n",
              "      <td>40</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>89</td>\n",
              "      <td>0.00685</td>\n",
              "      <td>0.02819</td>\n",
              "      <td>0.00718</td>\n",
              "      <td>0.01859</td>\n",
              "      <td>0.76616</td>\n",
              "      <td>1.20575</td>\n",
              "      <td>0.76821</td>\n",
              "      <td>1.12635</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.06535</td>\n",
              "      <td>0.78984</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.38040</td>\n",
              "      <td>0.74147</td>\n",
              "      <td>0.35050</td>\n",
              "      <td>0.73124</td>\n",
              "      <td>0.45126</td>\n",
              "      <td>44</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>0.00683</td>\n",
              "      <td>0.02827</td>\n",
              "      <td>0.00668</td>\n",
              "      <td>0.01906</td>\n",
              "      <td>0.74031</td>\n",
              "      <td>1.26830</td>\n",
              "      <td>0.74396</td>\n",
              "      <td>1.13324</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06517</td>\n",
              "      <td>0.80187</td>\n",
              "      <td>0.06258</td>\n",
              "      <td>0.39622</td>\n",
              "      <td>0.74955</td>\n",
              "      <td>0.34247</td>\n",
              "      <td>0.76792</td>\n",
              "      <td>0.44406</td>\n",
              "      <td>46</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>0.00684</td>\n",
              "      <td>0.02981</td>\n",
              "      <td>0.00721</td>\n",
              "      <td>0.01841</td>\n",
              "      <td>0.75492</td>\n",
              "      <td>1.29168</td>\n",
              "      <td>0.74225</td>\n",
              "      <td>1.11862</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.06456</td>\n",
              "      <td>0.87456</td>\n",
              "      <td>0.07095</td>\n",
              "      <td>0.37056</td>\n",
              "      <td>0.71750</td>\n",
              "      <td>0.34110</td>\n",
              "      <td>0.74416</td>\n",
              "      <td>0.44714</td>\n",
              "      <td>47</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>82</td>\n",
              "      <td>0.00746</td>\n",
              "      <td>0.02774</td>\n",
              "      <td>0.00695</td>\n",
              "      <td>0.01738</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>1.34581</td>\n",
              "      <td>0.77579</td>\n",
              "      <td>1.09954</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.07624</td>\n",
              "      <td>0.76268</td>\n",
              "      <td>0.06660</td>\n",
              "      <td>0.33706</td>\n",
              "      <td>0.69465</td>\n",
              "      <td>0.37617</td>\n",
              "      <td>0.75712</td>\n",
              "      <td>0.48599</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>85</td>\n",
              "      <td>0.00756</td>\n",
              "      <td>0.02682</td>\n",
              "      <td>0.00747</td>\n",
              "      <td>0.01779</td>\n",
              "      <td>0.74330</td>\n",
              "      <td>1.32099</td>\n",
              "      <td>0.78662</td>\n",
              "      <td>1.14457</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3886804-2be2-4222-9f94-d47cd515e41e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3886804-2be2-4222-9f94-d47cd515e41e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3886804-2be2-4222-9f94-d47cd515e41e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(datax, test_size=0.1)"
      ],
      "metadata": {
        "id": "8vqD2WFAxr1Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,:-1].to_numpy()\n",
        "y_train = train['output'].squeeze()\n",
        "X_test  = test.iloc[:,:-1].to_numpy()"
      ],
      "metadata": {
        "id": "VGZay6ud1kJu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet_params = dict(\n",
        "    n_d=64, n_a=64, n_steps=5,\n",
        "    gamma=1.5, n_independent=2, n_shared=2,    \n",
        "    cat_emb_dim=1,\n",
        "    lambda_sparse=1e-4, momentum=0.3, clip_value=2.,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params = {\"gamma\": 0.95,\n",
        "                     \"step_size\": 20},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
        ")"
      ],
      "metadata": {
        "id": "fuV2Ju6cx41y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(**tabnet_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oStvxMakzVDV",
        "outputId": "64cbe88c-62ce-4789-f814-8159ab982b82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = TabNetClassifier(verbose=0,seed=42)\n",
        "classifier.fit(X_train=X_train, y_train=y_train,\n",
        "               patience=5,max_epochs=100,\n",
        "               eval_metric=['auc'])\n",
        "\n",
        "predictions = classifier.predict_proba(X_test)[:,1]    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIiqSWUox5Ma",
        "outputId": "0933f0e6-f9b3-4ddb-a7c0-f5054b2956e8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save tabnet model\n",
        "saving_path_name = \"tabnet_model_test_\"\n",
        "saved_filepath = clf.save_model(saving_path_name)         "
      ],
      "metadata": {
        "id": "MBT4jsFxBram"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_clf = TabNetClassifier()\n",
        "loaded_clf.load_model('/content/tabnet_model_test_9.zip')\n",
        "y_pred=loaded_clf.predict_proba(X_test)\n",
        "test_acc = roc_auc_score(y_score=y_pred[:,1],y_true=y_test)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "_nu6Q2ntBGzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X6dtwsbnBG-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KpFPemyAiQP",
        "outputId": "b2c3efeb-62b9-4219-c7a8-5cd058f06d03"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.00862819e-01, 2.45288197e-06, 2.27237232e-02, 9.92795885e-01,\n",
              "       2.28544162e-03, 2.26500951e-08, 9.52023023e-04, 1.93406956e-03,\n",
              "       9.99423623e-01, 9.98595297e-01, 2.67691398e-08, 9.99217391e-01,\n",
              "       9.30204690e-01, 1.38154301e-05, 2.99012542e-01, 8.93136799e-01,\n",
              "       8.33437871e-03, 3.75248902e-02, 9.98939097e-01, 9.97732520e-01,\n",
              "       3.64331063e-04, 9.99989033e-01, 8.82415593e-01, 3.49201895e-02,\n",
              "       9.47538356e-05, 9.97696221e-01, 7.95180261e-01, 9.82551694e-01,\n",
              "       9.26288267e-05, 1.28818704e-02, 9.99757707e-01, 7.55235553e-02,\n",
              "       6.03912849e-05, 9.98850822e-01, 4.81041097e-05, 9.84081745e-01,\n",
              "       9.99644876e-01, 7.01681733e-01, 4.80172013e-10, 6.99209886e-06,\n",
              "       9.92003322e-01, 9.99324799e-01, 5.11507802e-02, 2.44442163e-06,\n",
              "       1.62560511e-02, 5.77241553e-06, 9.99079227e-01, 9.88328040e-01,\n",
              "       1.11415800e-04, 9.98541951e-01, 4.80392446e-05, 9.99959588e-01,\n",
              "       9.85479474e-01, 2.51540740e-04, 2.08368134e-02, 2.31770813e-04,\n",
              "       4.60137635e-08, 9.99937296e-01, 2.55007180e-03, 9.99067128e-01,\n",
              "       6.28703867e-10, 9.99402523e-01, 9.22442086e-06, 3.27768773e-01,\n",
              "       8.69692326e-01, 9.99368846e-01, 9.90778685e-01, 2.00376326e-06,\n",
              "       9.98295605e-01, 9.93609965e-01, 9.99766171e-01, 9.93645787e-01,\n",
              "       9.94727671e-01, 5.37393212e-01, 2.84523852e-02, 9.11216676e-01,\n",
              "       9.97887552e-01, 5.48709882e-04, 8.81154180e-01, 9.91068482e-01,\n",
              "       7.81180347e-07, 1.83263660e-06, 1.04012869e-01, 8.51283610e-01,\n",
              "       2.07158223e-01, 9.99778926e-01, 8.98536742e-01, 4.92630352e-06,\n",
              "       9.99211550e-01, 2.21584607e-02, 1.26649684e-04, 9.99947548e-01,\n",
              "       9.88986135e-01, 1.04544796e-02, 1.15449675e-05, 6.02180735e-05,\n",
              "       7.36932993e-01, 9.90686476e-01, 9.94018793e-01, 6.57962322e-01,\n",
              "       5.98292472e-03, 1.75397188e-04, 8.80087819e-03, 9.91511047e-01,\n",
              "       9.98454809e-01, 9.92731035e-01, 3.11602798e-06, 2.44046390e-01,\n",
              "       9.99887109e-01, 4.71255760e-07, 9.98931706e-01, 1.59911770e-06,\n",
              "       1.09632360e-02, 9.95424330e-01, 3.79313860e-04, 8.60359147e-03,\n",
              "       4.09027798e-08, 2.96448270e-05, 9.98442233e-01, 9.33190435e-02,\n",
              "       1.09326407e-04, 2.32020655e-04, 9.96548355e-01, 9.60047305e-01,\n",
              "       9.35534418e-01, 9.97656703e-01, 9.99958634e-01, 1.55933723e-02,\n",
              "       9.94789481e-01, 5.25235012e-02, 9.98202324e-01, 9.99922514e-01,\n",
              "       9.72755790e-01, 9.88805532e-01, 1.96535654e-09, 5.12310982e-01,\n",
              "       3.37138090e-07, 1.85954286e-05, 4.84865874e-01, 9.83078957e-01,\n",
              "       1.56492658e-03, 3.43091078e-02, 6.27913396e-05, 2.40566646e-06,\n",
              "       1.12984605e-01, 9.71555769e-01, 3.32854409e-03, 1.49857122e-08,\n",
              "       3.46026177e-08, 1.43760445e-07, 2.34701361e-07, 2.10702904e-02,\n",
              "       9.05463517e-01, 3.66929919e-01, 1.73429507e-04, 3.25324072e-06,\n",
              "       3.76499921e-01, 9.79035616e-01, 9.99951959e-01, 8.34506512e-01,\n",
              "       9.96685684e-01, 1.80674510e-06, 9.96843100e-01, 1.73193827e-01,\n",
              "       9.81785059e-01, 4.95969266e-10, 9.99231577e-01, 1.44831493e-01,\n",
              "       9.99775350e-01, 9.97369766e-01, 8.32227468e-01, 9.98883903e-01,\n",
              "       7.79089510e-01, 2.60607379e-07, 6.96952999e-01, 1.54053587e-02,\n",
              "       5.28029668e-05, 9.66370463e-01, 3.71911116e-02, 9.99710500e-01,\n",
              "       9.77878451e-01, 9.96979594e-01, 9.76582058e-03, 1.24826067e-04,\n",
              "       3.15676630e-02, 9.94370401e-01, 9.99979138e-01, 9.77504790e-01,\n",
              "       9.97351646e-01, 9.86015320e-01, 4.50144075e-02, 1.75557416e-02,\n",
              "       2.10108837e-07, 9.99650598e-01, 4.37985436e-04, 1.96074277e-01,\n",
              "       9.98104572e-01, 6.95700228e-01, 9.99609053e-01, 8.80301237e-01,\n",
              "       9.52825367e-01, 9.99551952e-01, 1.52842148e-07, 7.00531155e-03,\n",
              "       3.17783872e-07, 2.16946140e-01, 9.81577575e-01, 9.98215199e-01,\n",
              "       9.99964118e-01, 2.42076612e-06, 3.34963079e-09, 1.70168557e-09,\n",
              "       5.76724939e-04, 6.85763597e-01, 6.55006111e-01, 9.53669012e-01,\n",
              "       7.21799093e-04, 2.83240457e-04, 5.86368187e-05, 9.97336447e-01,\n",
              "       5.57187438e-01, 1.81923178e-06, 7.24281609e-01, 6.20794073e-02,\n",
              "       1.05720712e-04, 6.94762588e-01, 6.08760715e-01, 9.82111037e-01,\n",
              "       9.95144665e-01, 9.99072552e-01, 1.68591912e-03, 7.23736584e-01,\n",
              "       9.95003283e-01, 1.52898788e-01, 1.09037228e-05, 9.99871190e-05,\n",
              "       1.54235371e-04, 9.98909593e-01, 9.99487519e-01, 7.79376785e-10,\n",
              "       1.55905765e-02, 4.51695286e-02, 9.98850465e-01, 9.86887276e-01,\n",
              "       1.03163989e-02, 1.46221202e-02, 9.08246904e-04, 1.57414854e-01,\n",
              "       1.33662447e-01, 9.98682916e-01, 9.10001755e-01, 8.91697168e-01,\n",
              "       9.34722364e-01, 8.97974253e-01, 1.32856076e-04, 9.22807872e-01,\n",
              "       6.45803837e-08, 4.22028634e-08, 9.99886870e-01, 1.21539067e-02,\n",
              "       9.58150864e-01, 9.99974489e-01, 6.17003083e-01, 2.24618270e-06,\n",
              "       9.85669911e-01, 7.77141631e-01, 2.70676814e-09, 3.99265009e-05,\n",
              "       9.99649405e-01, 1.44528478e-01, 1.18164135e-05, 7.77583191e-05,\n",
              "       1.34599756e-03, 9.77983117e-01, 1.65741853e-02, 9.99362767e-01,\n",
              "       1.14173105e-04, 9.98781741e-01, 1.40571331e-07, 9.96580303e-01,\n",
              "       9.99993801e-01, 8.24769302e-08, 9.99666929e-01, 2.46089935e-01,\n",
              "       9.11896899e-02, 9.92294431e-01, 9.99962687e-01, 9.99938965e-01,\n",
              "       9.76543486e-01, 6.21359587e-01, 5.35815835e-01, 2.16365894e-08,\n",
              "       9.95624363e-01, 4.89349418e-07, 9.88854945e-01, 9.24480259e-01,\n",
              "       9.67824697e-01, 9.84118342e-01, 1.31111052e-02, 1.24472376e-06,\n",
              "       4.89021003e-01, 2.54541473e-03, 9.95568097e-01, 9.99665976e-01,\n",
              "       9.98415351e-01, 6.10617688e-03, 5.50996920e-04, 9.98235464e-01,\n",
              "       9.99939680e-01, 4.72420503e-09, 9.90398407e-01, 9.88572717e-01,\n",
              "       1.01904534e-05, 9.64988589e-01, 8.44630961e-08, 9.90985990e-01,\n",
              "       1.25760883e-02, 8.02924769e-05, 9.97728646e-01, 8.01752380e-04,\n",
              "       2.51226991e-01, 1.18163458e-04, 9.80014324e-01, 2.56469939e-02,\n",
              "       9.52102244e-01, 1.43270063e-06, 9.96368885e-01, 1.15991106e-09,\n",
              "       9.88715470e-01, 3.00293416e-01, 7.68774698e-05, 1.84196439e-02,\n",
              "       5.96856466e-04, 4.12386060e-01, 4.52159464e-01, 5.06610274e-01,\n",
              "       1.20932464e-06, 3.10165621e-02, 6.41590655e-01, 8.02865252e-02,\n",
              "       9.81238484e-01, 4.17317580e-07, 5.60524225e-01, 1.13698039e-02,\n",
              "       7.65889764e-01, 7.15369941e-09, 8.28726024e-06, 9.99975562e-01,\n",
              "       5.19139111e-01, 9.89489257e-01, 9.98762131e-01, 2.74206013e-05,\n",
              "       9.97747838e-01, 9.85899329e-01, 8.76370311e-01, 9.95954871e-01,\n",
              "       9.99994397e-01, 2.74851786e-09, 1.16706040e-04, 1.95588684e-03,\n",
              "       5.76934463e-06, 7.93150425e-01, 8.02713394e-01, 9.66474056e-01,\n",
              "       8.44082355e-01, 3.87234264e-04, 2.10698824e-02, 9.16113277e-06,\n",
              "       9.84373093e-01, 6.43445341e-09, 7.57389069e-01, 1.34887481e-02,\n",
              "       1.03313291e-09, 9.98872936e-01, 1.51017174e-01, 8.91505915e-04,\n",
              "       8.20270836e-01, 7.89910674e-01, 1.68914739e-05, 1.39003721e-04,\n",
              "       9.62386608e-01, 9.98935878e-01, 9.46536693e-06, 9.99743044e-01,\n",
              "       8.88413012e-01, 9.90545869e-01, 3.45386856e-04, 6.60289606e-06,\n",
              "       1.41112208e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample.iloc[:,1:] = predictions\n",
        "sample.to_csv('submission.csv',index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "BvVM7dPo3MP_",
        "outputId": "70af3c35-5ae7-495b-f218-f4a899e2b531"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b8395cdbe207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsX-RYXk3Mr6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}